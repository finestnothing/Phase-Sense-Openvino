{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from openvino.runtime import Core\n",
    "from statistics import mean\n",
    "import node as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLayers():\n",
    "    ie = Core()\n",
    "    classification_model_xml = \"./best.xml\"\n",
    "    model = ie.read_model(model=classification_model_xml)\n",
    "    compiled_model = ie.compile_model(model=model, device_name=\"CPU\") # CPU or MYRIAD\n",
    "    input_layer = compiled_model.input(0)\n",
    "    output_layer = compiled_model.output(0)\n",
    "    return input_layer, output_layer, compiled_model\n",
    "\n",
    "def build_model(is_cuda):\n",
    "    net = cv2.dnn.readNet(\"yolov5s.onnx\")\n",
    "    if is_cuda:\n",
    "        print(\"Attempty to use CUDA\")\n",
    "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA_FP16)\n",
    "    else:\n",
    "        print(\"Running on CPU\")\n",
    "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "    return net\n",
    "\n",
    "def detect(image, input_layer, output_layer, compiled_model):\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (INPUT_WIDTH, INPUT_HEIGHT), swapRB=True, crop=False)\n",
    "    preds = compiled_model([blob])[output_layer]\n",
    "    return preds\n",
    "\n",
    "def load_capture(video_path):\n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "    return capture\n",
    "\n",
    "def load_classes():\n",
    "    class_list = []\n",
    "    with open(\"classes.txt\", \"r\") as f:\n",
    "        class_list = [cname.strip() for cname in f.readlines()]\n",
    "    return class_list\n",
    "\n",
    "def wrap_detection(input_image, output_data):\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    rows = output_data.shape[0]\n",
    "\n",
    "    image_width, image_height, _ = input_image.shape\n",
    "\n",
    "    x_factor = image_width / INPUT_WIDTH\n",
    "    y_factor =  image_height / INPUT_HEIGHT\n",
    "\n",
    "    for r in range(rows):\n",
    "        row = output_data[r]\n",
    "        confidence = row[4]\n",
    "        if confidence >= 0.4:\n",
    "\n",
    "            classes_scores = row[5:]\n",
    "            _, _, _, max_indx = cv2.minMaxLoc(classes_scores)\n",
    "            class_id = max_indx[1]\n",
    "            if (classes_scores[class_id] > .25):\n",
    "\n",
    "                confidences.append(confidence)\n",
    "\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "                x, y, w, h = row[0].item(), row[1].item(), row[2].item(), row[3].item() \n",
    "                left = int((x - 0.5 * w) * x_factor)\n",
    "                top = int((y - 0.5 * h) * y_factor)\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "                box = np.array([left, top, width, height])\n",
    "                boxes.append(box)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.25, 0.45) \n",
    "\n",
    "    result_class_ids = []\n",
    "    result_confidences = []\n",
    "    result_boxes = []\n",
    "\n",
    "    for i in indexes:\n",
    "        result_confidences.append(confidences[i])\n",
    "        result_class_ids.append(class_ids[i])\n",
    "        result_boxes.append(boxes[i])\n",
    "\n",
    "    return result_class_ids, result_confidences, result_boxes\n",
    "\n",
    "def format_yolov5(frame):\n",
    "\n",
    "    row, col, _ = frame.shape\n",
    "    _max = max(col, row)\n",
    "    result = np.zeros((_max, _max, 3), np.uint8)\n",
    "    result[0:row, 0:col] = frame\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_WIDTH = 640\n",
    "INPUT_HEIGHT = 640\n",
    "SCORE_THRESHOLD = 0.2\n",
    "NMS_THRESHOLD = 0.4\n",
    "CONFIDENCE_THRESHOLD = 0.7\n",
    "LIGHT_CALIBRATION_FRAME_COUNT = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration Complete\n",
      "could not create node\n",
      "Node not found\n",
      "ERROR: Node not yet initialized.\n",
      "Light added\n",
      "ERROR: Node not yet initialized.\n",
      "Light added\n",
      "ERROR: Node not yet initialized.\n",
      "Light added\n",
      "ERROR: Node not yet initialized.\n",
      "Light added\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "0  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "1  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "2  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "3  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "0  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "1  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "2  -  0\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "3  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "0  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "1  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "2  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "3  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "0  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "1  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "2  -  0\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "3  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "0  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "1  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "2  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "3  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "0  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "1  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "2  -  0\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "3  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "0  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "1  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "2  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "3  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "0  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "1  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "2  -  0\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "3  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "0  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "1  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "2  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "3  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "0  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "1  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "2  -  0\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "3  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "0  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "1  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "2  -  1\n",
      "404 Client Error: Not Found for url: http://localhost:3000/api/node/light?nodeId=0\n",
      "3  -  1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0d57fca49efa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompiled_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mclass_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrap_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mframe_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-67a85c2361c5>\u001b[0m in \u001b[0;36mwrap_detection\u001b[1;34m(input_image, output_data)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mclasses_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_indx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminMaxLoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m             \u001b[0mclass_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_indx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mclasses_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "class_list = load_classes()\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 255, 255), (255, 0, 0)]\n",
    "\n",
    "# is_cuda = len(sys.argv) > 1 and sys.argv[1] == \"cuda\"\n",
    "\n",
    "# net = build_model(is_cuda)\n",
    "capture = load_capture(\"test_data/chloe_video.MOV\")\n",
    "\n",
    "start = time.time_ns()\n",
    "frame_count = 0\n",
    "total_frames = 0\n",
    "fps = -1\n",
    "input_layer, output_layer, compiled_model = getLayers()\n",
    "\n",
    "lights_holder = [] # [[light_id, x, y, count], ...]\n",
    "lights = [] # Holds mean of all light positions\n",
    "frame_data_holder = []  # Holds data for multiple frames to find averages\n",
    "current_state = []\n",
    "\n",
    "while True:\n",
    "\n",
    "    _, vid_frame = capture.read()\n",
    "    if vid_frame is None:\n",
    "        print(\"End of stream\")\n",
    "        break\n",
    "\n",
    "    inputImage = format_yolov5(vid_frame)\n",
    "    \n",
    "    outs = detect(inputImage, input_layer, output_layer, compiled_model)\n",
    "\n",
    "    class_ids, confidences, boxes = wrap_detection(inputImage, outs[0])\n",
    "\n",
    "    frame_count += 1\n",
    "    total_frames += 1\n",
    "    \n",
    "    frame_data = [] # [class_id, confidence, box] for each frame\n",
    "    for (classid, confidence, box) in zip(class_ids, confidences, boxes):\n",
    "        frame_data.append([class_list[classid], confidence, box])\n",
    "        \n",
    "    \n",
    "    if total_frames < LIGHT_CALIBRATION_FRAME_COUNT: # If we haven't collected enough data yet, continue collecting frame data\n",
    "        frame_data_holder.append(frame_data)\n",
    "    elif total_frames == LIGHT_CALIBRATION_FRAME_COUNT: # If we have collected enough data, calculate averages and find lights\n",
    "        print(\"Calibration Complete\")\n",
    "        for frame in frame_data_holder: # Check all collected frames\n",
    "            for frame_line in frame: # Check each line of each frame\n",
    "                added = False # Used to check if line has been added to lights_holder yet\n",
    "                for light in lights_holder: # Check each light in lights_holder\n",
    "                    if abs(frame_line[2][0] - mean(light[1])) < 200: # If X is within 200 of the light\n",
    "                        if frame_line[2][1] < mean(light[2]) - 250: # If Y is significantly lower, do not add it\n",
    "                            continue # Light not added, but not attributed to any other light either\n",
    "                        elif frame_line[2][1] < mean(light[2]) + 500: # If Y not significantly higher, add it\n",
    "                            light[1].append(frame_line[2][0])\n",
    "                            light[2].append(frame_line[2][1])\n",
    "                            light[3] += 1\n",
    "                        elif frame_line[2][1] > mean(light[2]) + 500: # If Y is significantly higher, overwrite data for light\n",
    "                            light[1] = [frame_line[2][0]]\n",
    "                            light[2] = [frame_line[2][1]]\n",
    "                            light[3] = 1\n",
    "                        added = True\n",
    "                    if added == True:\n",
    "                        break\n",
    "                if not added:\n",
    "                    lights_holder.append([len(lights_holder), [frame_line[2][0]], [frame_line[2][1]], 1]) # Add new light if no X's are near\n",
    "                    \n",
    "        # Aggregate data for each light\n",
    "        for light in lights_holder:\n",
    "            lights.append([light[0], mean(light[1]), mean(light[2]), light[3]])\n",
    "        # for i in range(len(lights)): # If light has been seen in less than 1/5 of frames, remove it\n",
    "        #     if lights[i][3] < LIGHT_CALIBRATION_FRAME_COUNT/5:\n",
    "        #         del lights[i]\n",
    "        lights = [item for item in lights if item[3] > LIGHT_CALIBRATION_FRAME_COUNT/5] # Remove lights that have been seen in less than 1/5 of frames\n",
    "\n",
    "        # Setup node and lights\n",
    "        if not os.path.exists(\"node_data.json\"):\n",
    "            nd.init_node(\"State University Ave\", \"000.000.0.0\")\n",
    "            \n",
    "        if not os.path.exists(\"lights.json\"):\n",
    "            for x in lights:\n",
    "                nd.create_light(0, 0)\n",
    "        \n",
    "        current_state = [None] * len(lights) # Initialize array to keep track of states\n",
    "            \n",
    "    else: # To run after initial calibration\n",
    "        # For each light\n",
    "        temp = [0] * len(lights)\n",
    "        for light in lights:\n",
    "            updated = False # Used to check if light has been updated\n",
    "            # Look at each line in frame_data, attempt to match them to the light\n",
    "            for line in frame_data:\n",
    "                if abs(line[2][0] - light[1]) < 200 and line[2][1] > light[2] - 100:\n",
    "                    temp[int(light[0])] = line[0] # Set state\n",
    "                    # print(\"Light\", light[0], \"set to\", line[0])\n",
    "                    updated = True\n",
    "                    break\n",
    "            if not updated:\n",
    "                temp[int(light[0])] = 0 # Set state to 0 if no match found\n",
    "                # print(\"Light\", light[0], \"set to 0\")\n",
    "                # for line in frame_data:\n",
    "                #     print(\"x: \", abs(line[2][0] - light[1]))\n",
    "                #     print(\"y: \", line[2][1] - light[2])\n",
    "                \n",
    "        # When done with checking all lights, compare to current_state\n",
    "        if temp != current_state:\n",
    "            current_state = temp\n",
    "            for i in range(len(current_state)):\n",
    "                nd.patch_light(str(i), current_state[i])\n",
    "                # print(i, \" - \", current_state[i])\n",
    "\n",
    "\n",
    "    ###############################################################################\n",
    "    # Begininning of code for displaying cv2 annotated window\n",
    "    ###############################################################################\n",
    "    for (classid, confidence, box) in zip(class_ids, confidences, boxes):\n",
    "        color = colors[0]\n",
    "        cv2.rectangle(vid_frame, box, color, 2)\n",
    "        cv2.rectangle(vid_frame, (box[0], box[1] - 20), (box[0] + box[2], box[1]), color, -1)\n",
    "        cv2.putText(vid_frame, class_list[classid], (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,0,0))\n",
    "\n",
    "    if frame_count >= 30:\n",
    "        end = time.time_ns()\n",
    "        fps = 1000000000 * frame_count / (end - start)\n",
    "        frame_count = 0\n",
    "        start = time.time_ns()\n",
    "    \n",
    "    if fps > 0:\n",
    "        fps_label = \"FPS: %.2f\" % fps\n",
    "        cv2.putText(vid_frame, fps_label, (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL) \n",
    "\n",
    "    cv2.imshow(\"output\", vid_frame)\n",
    "    ###############################################################################\n",
    "    # End of code for displaying cv2 annotated window\n",
    "    ###############################################################################\n",
    "    \n",
    "    if cv2.waitKey(1) > -1:\n",
    "        print(\"finished by user\")\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "304a6a39a4dadf08983ed4ac6f349dfa86009ff63eff805aea7a9385acc38647"
  },
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
